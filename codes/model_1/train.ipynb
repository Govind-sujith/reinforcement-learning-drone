{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c17db4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# train.py\n",
    "from env import DroneEnv\n",
    "from models import Actor, Critic\n",
    "from replay_buffer import ReplayBuffer\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "env = DroneEnv()\n",
    "\n",
    "img_shape = (3, 84, 84)\n",
    "action_dim = 4\n",
    "actor = Actor(img_shape, action_dim).to(device)\n",
    "critic1 = Critic(img_shape, action_dim).to(device)\n",
    "critic2 = Critic(img_shape, action_dim).to(device)\n",
    "actor_opt = optim.Adam(actor.parameters(), lr=3e-4)\n",
    "critic1_opt = optim.Adam(critic1.parameters(), lr=3e-4)\n",
    "critic2_opt = optim.Adam(critic2.parameters(), lr=3e-4)\n",
    "\n",
    "replay = ReplayBuffer(100000, img_shape, action_dim)\n",
    "\n",
    "gamma = 0.99\n",
    "alpha = 0.2  # entropy regularization\n",
    "batch_size = 64\n",
    "\n",
    "for episode in range(1000):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        img = torch.tensor(state.transpose(2, 0, 1)).unsqueeze(0).to(device, dtype=torch.float32)\n",
    "        action = actor(img).squeeze().detach().cpu().numpy()\n",
    "        next_state, reward, done = env.step(action)\n",
    "\n",
    "        replay.add(state, action, reward, next_state, done)\n",
    "        state = next_state\n",
    "\n",
    "        if replay.size > batch_size:\n",
    "            s, a, r, s2, d = replay.sample(batch_size)\n",
    "            s = torch.tensor(s.transpose(0, 3, 1, 2)).to(device)\n",
    "            a = torch.tensor(a).to(device)\n",
    "            r = torch.tensor(r).to(device)\n",
    "            s2 = torch.tensor(s2.transpose(0, 3, 1, 2)).to(device)\n",
    "            d = torch.tensor(d).to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                next_action = actor(s2)\n",
    "                target_q1 = critic1(s2, next_action)\n",
    "                target_q2 = critic2(s2, next_action)\n",
    "                target_q = r + gamma * (1 - d) * torch.min(target_q1, target_q2)\n",
    "\n",
    "            # Critic update\n",
    "            q1 = critic1(s, a)\n",
    "            q2 = critic2(s, a)\n",
    "            critic1_loss = F.mse_loss(q1, target_q)\n",
    "            critic2_loss = F.mse_loss(q2, target_q)\n",
    "\n",
    "            critic1_opt.zero_grad()\n",
    "            critic1_loss.backward()\n",
    "            critic1_opt.step()\n",
    "\n",
    "            critic2_opt.zero_grad()\n",
    "            critic2_loss.backward()\n",
    "            critic2_opt.step()\n",
    "\n",
    "            # Actor update\n",
    "            actor_loss = -critic1(s, actor(s)).mean()\n",
    "            actor_opt.zero_grad()\n",
    "            actor_loss.backward()\n",
    "            actor_opt.step()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
